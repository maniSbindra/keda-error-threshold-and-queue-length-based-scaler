apiVersion: keda.sh/v1alpha1
kind: ScaledObject
metadata:
  name: keda-multi-metrics-scaler
spec:
  scaleTargetRef:
    # name: kotlin-deployment
    apiVersion: apps/v1
    kind: Deployment
    name: go-rest-api-deployment
  pollingInterval: 20 # Must be seconds
  minReplicaCount: 2
  maxReplicaCount: 7
  cooldownPeriod:  30
  triggers:
  - type: prometheus
    metadata:
      serverAddress: http://prometheus-server.prometheus.svc.cluster.local:80
      # metricName: pod_memory_percentage_usage_kotlin
      threshold: '20'
      query: (msg_queue_length)*(clamp_min(clamp_max((rate_429_errors < 5),1),1)) OR on() vector(0)
      # The above query returns the queue length if the rate of errors is less than the threshold, else the query returns 0, which stops scale up and 
      # initiates scale down